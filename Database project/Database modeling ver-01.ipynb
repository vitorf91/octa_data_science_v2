{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meeting Pattern\n",
    "\n",
    "O objetivo deste projeto é identificar qual o padrão dos leads para que haja conexão e agendamento, ou seja, geração de oportunidade.\n",
    "\n",
    "Abordaremos desta maneira devido ao objetivo de melhorar a taxa de conversão entre um lead gerado e qualificado por marketing até a oportunidade gerada. Além disso, o volume é muito maior quando se comparado com o número de clientes, dando uma possibilidade de um estudo ainda mais consistente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rd = pd.read_csv('data/rdstation.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "events = pd.read_csv('data/conversoes.csv', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exact = pd.read_csv('data/exact_v2.csv', sep=';', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56524, 166)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rd.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento das bases\n",
    "\n",
    "1) RD Station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Dropar todas as colunas que não possuem nenhuma informação\n",
    "rd = rd.dropna(axis=1, how='all')\n",
    "\n",
    "#selecionar todas as colunas que possuem + 300 eventos registrados\n",
    "rd = rd[rd.columns[rd.count()>300]]\n",
    "\n",
    "#dropar as colunas que não utilizamos para analisar os dados\n",
    "rd.drop(labels=['Celular', 'Cidade', 'Estado', 'Pais', 'Mercado', 'Produto', 'Dadoscoletados', 'Origem.1', 'Company', \\\n",
    "                    'Id', 'Trialstart', 'Trialend', 'Import token', 'Submit-om', 'Possui-sistema-de-atendimento', \\\n",
    "                    'Newsletter', 'Form url', 'Siteempresa','Created at', 'Page title', 'Conversion page', 'Istest', 'Tags', \\\n",
    "                    'Octadesksubdomain', 'Message', 'Octadeskemail', 'Istrial', 'Hascreatedaccount', 'Traffic Source', \\\n",
    "                    'Sh0uldn07ch4ng3', 'Custom fields[274]', 'Custom fields[14137]', \\\n",
    "                    'Custom fields[28126]', 'Custom fields[28308]', 'Custom fields[266]', \\\n",
    "                    'Custom fields[270]', 'Custom fields[268]', 'Qual seu maior problema?', \\\n",
    "                    'Custom fields[148136]', 'Vertical', 'Já utiliza sistema de atendimento?', \\\n",
    "                    'Custom fields[98378]', 'Custom fields[15144]', 'Custom fields[16314]', 'Field 0 hidden', 'Field 1 hidden', \\\n",
    "                    'Dores', 'Motivodescarte', 'Etapadescarte', 'Prevendedor', 'Emailprevendedor',\\\n",
    "                    'Qualificacaofiltro1','Qualificacaofiltro2', 'Qualificacaofeedbackvisita', 'Etapaatual','Vendedor'], axis=1, inplace=True)\n",
    "\n",
    "#Splitar a Origem e criar duas colunas\n",
    "#medium\n",
    "rd['rd_medium'] = rd['Origem'].str.split('|').str[0]\n",
    "rd['rd_medium'] = rd['rd_medium'].str.strip()\n",
    "\n",
    "#source\n",
    "rd['rd_source'] = rd['Origem'].str.split('|').str[1]\n",
    "rd['rd_source'] = rd['rd_source'].str.strip()\n",
    "\n",
    "#drop Origem\n",
    "rd.drop(labels=['Origem'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Normalizar a data de conversão\n",
    "rd['conv_date'] = pd.DatetimeIndex(rd['Data da Conversão']).normalize()\n",
    "conv_date = rd['conv_date']\n",
    "rd['conv_date'] = pd.to_datetime(rd['conv_date'], format='%d/%m/%Y')\n",
    "rd.drop(labels=['conv_date', 'Data da Conversão'], axis=1,inplace = True)\n",
    "rd.insert(0, 'conv_date', conv_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#renomear as colunas\n",
    "rd = rd.rename(index=str, columns={'Identificador': 'event', 'Nome': 'name', \\\n",
    "                                  'Telefone': 'phone', 'Utm campaign': 'utm_campaign', \\\n",
    "                                  'Utm medium': 'utm_medium', 'Utm source':'utm_source', \\\n",
    "                                  'Email lead': 'email', 'Website': 'site', \\\n",
    "                                  'Qual é o seu cargo?': 'job_title', 'Departamento': 'department',\n",
    "                                  'Numero-de-funcionarios': 'n_employees', 'Gerenciamento': 'management',\n",
    "                                  'Utm content': 'utm_content', 'Utm term': 'utm_term',\n",
    "                                  'Número de funcionários': 'n_employees 2', 'Empresa': 'company_name'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Juntar as colunas de número de funcionários\n",
    "rd['n_employees'] = rd[['n_employees', 'n_employees 2']].apply(lambda x: ','.join(x.dropna().astype(str)),axis=1)\n",
    "rd.drop('n_employees 2', axis=1, inplace = True)\n",
    "\n",
    "#Juntar as colunas de cargo\n",
    "rd['job_title'] = rd[['Cargo', 'job_title']].apply(lambda x: ','.join(x.dropna().astype(str)),axis=1)\n",
    "rd.drop('Cargo', axis=1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#employee\n",
    "rd['n_employees'].replace('1 a 10', '1-10', inplace=True)\n",
    "rd['n_employees'].replace('11 a 30', '11-30', inplace=True)\n",
    "rd['n_employees'].replace('de 11 a 30 ', '11-30', inplace=True)\n",
    "rd['n_employees'].replace('de 6 a 10', '1-10', inplace=True)\n",
    "rd['n_employees'].replace('de 6 a 10 ', '1-10', inplace=True)\n",
    "rd['n_employees'].replace('6 a 10', '6-10', inplace=True)\n",
    "rd['n_employees'].replace('1 a 5', '1-5', inplace=True)\n",
    "rd['n_employees'].replace('de 1 a 5', '1-5', inplace=True)\n",
    "rd['n_employees'].replace('31 a 50', '31-50', inplace=True)\n",
    "rd['n_employees'].replace('51 a 100', '51-100', inplace=True)\n",
    "rd['n_employees'].replace('acima de 1001', '101+', inplace=True)\n",
    "rd['n_employees'].replace('251 a 500', '101+', inplace=True)\n",
    "rd['n_employees'].replace('de 251 a 500', '101+', inplace=True)\n",
    "rd['n_employees'].replace('de 101 a 250', '101+', inplace=True)\n",
    "rd['n_employees'].replace('500 a 1000', '101+', inplace=True)\n",
    "rd['n_employees'].replace('101 a 250', '101+', inplace=True)\n",
    "rd['n_employees'].replace('de 501 a 1000', '101+', inplace=True)\n",
    "rd['n_employees'].replace('1-5', '1-5', inplace=True)\n",
    "rd['n_employees'].replace('6-10', '6-10', inplace=True)\n",
    "rd['n_employees'].replace('11-20', '11-30', inplace=True)\n",
    "rd['n_employees'].replace('Mais de 20', '11-30', inplace=True)\n",
    "rd['n_employees'].replace('undefined', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#outros cargos\n",
    "rd['job_title'].replace('CONSULTOR', 'Outros Cargos', inplace=True)\n",
    "rd['job_title'].replace('Consultor', 'Outros Cargos', inplace=True)\n",
    "rd['job_title'].replace('Assistente Comercial', 'Outros Cargos', inplace=True)\n",
    "rd['job_title'].replace('Administração', 'Outros Cargos', inplace=True)\n",
    "rd['job_title'].replace('Representante', 'Outros Cargos', inplace=True)\n",
    "rd['job_title'].replace('Consultor Empresarial', 'Outros Cargos', inplace=True)\n",
    "rd['job_title'].replace('Representante Comercial', 'Outros Cargos', inplace=True)\n",
    "rd['job_title'].replace('Outros cargos', 'Outros Cargos', inplace=True)\n",
    "rd['job_title'].replace('Outro', 'Outros Cargos', inplace=True)\n",
    "rd['job_title'].replace('undefined', 'Outros Cargos', inplace=True)\n",
    "\n",
    "\n",
    "#coordenador\n",
    "rd['job_title'].replace('Supervisor(a) / Coordenador(a)', 'Supervisor', inplace=True)\n",
    "rd.loc[rd['job_title'].str.contains('supervisor'), 'job_title'] = 'Supervisor'\n",
    "rd.loc[rd['job_title'].str.contains('Supervisor'), 'job_title'] = 'Supervisor'\n",
    "rd.loc[rd['job_title'].str.contains('SUPERVISOR'), 'job_title'] = 'Supervisor'\n",
    "\n",
    "#socio\n",
    "rd['job_title'].replace('Empresário / CEO', 'Sócio / CEO', inplace=True)\n",
    "rd['job_title'].replace('Executivo', 'Sócio / CEO', inplace=True)\n",
    "rd['job_title'].replace('propietario', 'Sócio / CEO', inplace=True)\n",
    "rd['job_title'].replace('Presidência', 'Sócio / CEO', inplace=True)\n",
    "rd['job_title'].replace('CEO', 'Sócio / CEO', inplace=True)\n",
    "rd.loc[rd['job_title'].str.contains('ceo'), 'job_title'] = 'Sócio / CEO'\n",
    "rd.loc[rd['job_title'].str.contains('Ceo'), 'job_title'] = 'Sócio / CEO'\n",
    "rd.loc[rd['job_title'].str.contains('CEO'), 'job_title'] = 'Sócio / CEO'\n",
    "rd.loc[rd['job_title'].str.contains('Sócio'), 'job_title'] = 'Sócio / CEO'\n",
    "rd.loc[rd['job_title'].str.contains('sócio'), 'job_title'] = 'Sócio / CEO'\n",
    "rd.loc[rd['job_title'].str.contains('SÓCIO'), 'job_title'] = 'Sócio / CEO'\n",
    "rd.loc[rd['job_title'].str.contains('Socio'), 'job_title'] = 'Sócio / CEO'\n",
    "rd.loc[rd['job_title'].str.contains('socio'), 'job_title'] = 'Sócio / CEO'\n",
    "rd.loc[rd['job_title'].str.contains('SOCIO'), 'job_title'] = 'Sócio / CEO'\n",
    "rd.loc[rd['job_title'].str.contains('SÛcio'), 'job_title'] = 'Sócio / CEO'\n",
    "rd.loc[rd['job_title'].str.contains('Dono'), 'job_title'] = 'Sócio / CEO'\n",
    "rd.loc[rd['job_title'].str.contains('Owner'), 'job_title'] = 'Sócio / CEO'\n",
    "rd.loc[rd['job_title'].str.contains('Founder'), 'job_title'] = 'Sócio / CEO'\n",
    "rd.loc[rd['job_title'].str.contains('founder'), 'job_title'] = 'Sócio / CEO'\n",
    "rd.loc[rd['job_title'].str.contains('Proprietário'), 'job_title'] = 'Sócio / CEO'\n",
    "rd.loc[rd['job_title'].str.contains('Propietário'), 'job_title'] = 'Sócio / CEO'\n",
    "rd.loc[rd['job_title'].str.contains('Presidente'), 'job_title'] = 'Sócio / CEO'\n",
    "rd.loc[rd['job_title'].str.contains('presidente'), 'job_title'] = 'Sócio / CEO'\n",
    "\n",
    "#Diretor\n",
    "rd['job_title'].replace('Diretor Comercial', 'Diretor', inplace=True)\n",
    "rd.loc[rd['job_title'].str.contains('Diretor'), 'job_title'] = 'Diretor'\n",
    "rd.loc[rd['job_title'].str.contains('DIRETOR'), 'job_title'] = 'Diretor'\n",
    "rd.loc[rd['job_title'].str.contains('diretor'), 'job_title'] = 'Diretor'\n",
    "\n",
    "#gerente\n",
    "rd['job_title'].replace('Gerente de Vendas', 'Gerente', inplace=True)\n",
    "rd['job_title'].replace('Gestor de Vendas', 'Gerente', inplace=True)\n",
    "rd['job_title'].replace('Gestor de Marketing', 'Gerente', inplace=True)\n",
    "rd.loc[rd['job_title'].str.contains('Gerente'), 'job_title'] = 'Gerente'\n",
    "rd.loc[rd['job_title'].str.contains('gerente'), 'job_title'] = 'Gerente'\n",
    "rd.loc[rd['job_title'].str.contains('GERENTE'), 'job_title'] = 'Gerente'\n",
    "rd.loc[rd['job_title'].str.contains('Responsável'), 'job_title'] = 'Gerente'\n",
    "rd.loc[rd['job_title'].str.contains('GESTOR'), 'job_title'] = 'Gerente'\n",
    "rd.loc[rd['job_title'].str.contains('gestor'), 'job_title'] = 'Gerente'\n",
    "rd.loc[rd['job_title'].str.contains('Gestor'), 'job_title'] = 'Gerente'\n",
    "\n",
    "\n",
    "#vendedor / atendente\n",
    "rd['job_title'].replace('vendedor', 'Vendedor / atendente', inplace=True)\n",
    "rd['job_title'].replace('Atendente', 'Vendedor / atendente', inplace=True)\n",
    "rd['job_title'].replace('Vendedor Externo', 'Vendedor / atendente', inplace=True)\n",
    "rd['job_title'].replace('Vendedor Interno', 'Vendedor / atendente', inplace=True)\n",
    "\n",
    "#analista\n",
    "rd.loc[rd['job_title'].str.contains('Analista'), 'job_title'] = 'Analista'\n",
    "rd.loc[rd['job_title'].str.contains('analista'), 'job_title'] = 'Analista'\n",
    "rd.loc[rd['job_title'].str.contains('ANALISTA'), 'job_title'] = 'Analista'\n",
    "\n",
    "#Coordenador\n",
    "rd.loc[rd['job_title'].str.contains('Coordenador'), 'job_title'] = 'Coordenador'\n",
    "rd.loc[rd['job_title'].str.contains('coordenador'), 'job_title'] = 'Coordenador'\n",
    "rd.loc[rd['job_title'].str.contains('COORDENADOR'), 'job_title'] = 'Coordenador'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Somar Todos os valores abaixo de 15 para Outros Cargos\n",
    "g = rd.groupby('job_title')\n",
    "g.filter(lambda x: len(x) <= 15)\n",
    "rd.loc[g['job_title'].transform(lambda x: len(x) <= 15).astype(bool), 'job_title'] = 'Outros Cargos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remover '/' dos eventos\n",
    "rd.event.replace(regex=True,inplace=True,to_replace=r'/',value=r'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Substituir medium de Social para Facebook ou LinkedIn\n",
    "rd.rd_medium.replace('Social', rd.rd_source, inplace=True)\n",
    "\n",
    "#Substituir Desconhecido para utm_medium\n",
    "rd.rd_medium.replace('Desconhecido', rd.utm_medium, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#substituir valores de utm_medium para o padrão RD\n",
    "rd.rd_medium.replace('social', rd.utm_source, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cargo -> 'Custom fields[44611]'\n",
    "rd.job_title.replace(np.nan, rd['Custom fields[44611]'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#area -> Custom fields[44612]\n",
    "rd.department.replace(np.nan, rd['Custom fields[44612]'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#quantidade funcionário Custom fields[265]\n",
    "rd.n_employees.replace(np.nan, rd['Custom fields[265]'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd.job_title.replace(r'', np.nan, regex=True, inplace=True)\n",
    "rd.n_employees.replace(r'', np.nan, regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#substituir valores para grupos maiores\n",
    "rd.rd_medium.replace('cpc', 'Busca Paga', inplace=True)\n",
    "rd.rd_medium.replace('organic', 'Busca Orgânica', inplace=True)\n",
    "rd.rd_medium.replace('email', 'Email', inplace=True)\n",
    "rd.rd_medium.replace('cpc', 'Busca Paga', inplace=True)\n",
    "rd.rd_medium.replace('facebook', 'Facebook', inplace=True)\n",
    "rd.rd_medium.replace('referral', 'Referência', inplace=True)\n",
    "rd.rd_medium.replace('linkedin', 'LinkedIn', inplace=True)\n",
    "rd.rd_medium.replace('Facebook Ads', 'Facebook', inplace=True)\n",
    "rd.rd_medium.replace('n/a', 'Desconhecido', inplace=True)\n",
    "rd.rd_medium.replace('none', 'Desconhecido', inplace=True)\n",
    "rd.rd_medium.replace('banner-blog', 'Desconhecido', inplace=True)\n",
    "rd.rd_medium.replace('blog', 'Desconhecido', inplace=True)\n",
    "rd.rd_medium.replace('Instagram', 'Desconhecido', inplace=True)\n",
    "rd.rd_medium.replace('link-site', 'Desconhecido', inplace=True)\n",
    "rd.rd_medium.replace('button-site', 'Desconhecido', inplace=True)\n",
    "rd.rd_medium.replace('Twitter', 'Desconhecido', inplace=True)\n",
    "rd.rd_medium.replace('Pinterest', 'Desconhecido', inplace=True)\n",
    "rd.rd_medium.replace('Partner', 'Email', inplace=True)\n",
    "rd.rd_medium.replace('link-blog', 'Email', inplace=True)\n",
    "rd.rd_medium.replace('Blogger', 'Email', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rd.rd_medium.fillna('Desconhecido', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) a) Eventos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "events = pd.read_excel('data/events 2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dropar a coluna ID\n",
    "events.drop('ID', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#criar uma coluna na base RD com a classificação dos materiais\n",
    "#rd = rd.merge(events, how='left', on=\"event\")\n",
    "rd_events = events.drop_duplicates('event', keep='first').set_index('event')['funnel']\n",
    "rd['funnel'] = rd['event'].map(rd_events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Exact Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropar todas as colunas que não possuem nenhuma informação\n",
    "exact = exact.dropna(axis=1, how='all')\n",
    "\n",
    "#Dropar as colunas que não necessitam para a análise\n",
    "exact.drop(labels=['Nome da Empresa', 'Dt. Venda', 'Dt. Última Atualização',\\\n",
    "                   'Produto', 'Site', 'Data Descarte', 'LinkMarketing', 'Motivo descarte',\\\n",
    "                   'País', 'Estado', 'Cidade', 'Telefone 1', 'Telefone 2', 'Observação',\\\n",
    "                   'Dores Lead', 'Produtos Sugeridos', 'Produtos Vendidos','Cargo Contato 1',\\\n",
    "                   'Telefone 1 Contato 1', 'Telefone 2 Contato 1', 'Nome Contato 2',\\\n",
    "                   'E-mail Contato 2', 'Cargo Contato 2', 'Telefone 1 Contato 2',\\\n",
    "                   'Telefone 2 Contato 2', 'Nome Contato 3', 'E-mail Contato 3','Nome Contato 1',\\\n",
    "                   'Cargo Contato 3', 'Telefone 1 Contato 3', 'E-mail Pré-vendedor', \\\n",
    "                    'Telefone 2 Contato 3', 'Dt. Último Resgate'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Ajuste das datas para padrão d/m/Y\n",
    "\n",
    "#create date\n",
    "exact['Data de Criação'] = pd.to_datetime(exact['Data de Criação'], format='%d/%m/%Y')\n",
    "\n",
    "#booking date\n",
    "exact['Dt. Agend. reunião'] = exact['Dt. Agend. reunião'].str.split(' ').str[0]\n",
    "exact['Dt. Agend. reunião'] = pd.to_datetime(exact['Dt. Agend. reunião'], format='%d/%m/%Y')\n",
    "\n",
    "#meeting date\n",
    "exact['Dt. Reunião'] = exact['Dt. Reunião'].str.split(' ').str[0]\n",
    "exact['Dt. Reunião'] = pd.to_datetime(exact['Dt. Reunião'], format='%d/%m/%Y')\n",
    "\n",
    "#feedback date\n",
    "exact['Dt. Preenc. Feedback'] = exact['Dt. Preenc. Feedback'].str.split(' ').str[0]\n",
    "exact['Dt. Preenc. Feedback'] = pd.to_datetime(exact['Dt. Preenc. Feedback'], format='%d/%m/%Y')\n",
    "\n",
    "#filter 1 date\n",
    "exact['Dt. Filtro 1'] = exact['Dt. Filtro 1'].str.split(' ').str[0]\n",
    "exact['Dt. Filtro 1'] = pd.to_datetime(exact['Dt. Filtro 1'], format='%d/%m/%Y')\n",
    "\n",
    "#filter 2 date\n",
    "exact['Dt. Filtro 2'] = exact['Dt. Filtro 2'].str.split(' ').str[0]\n",
    "exact['Dt. Filtro 2'] = pd.to_datetime(exact['Dt. Filtro 2'], format='%d/%m/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Renomear as colunas\n",
    "#renomear as colunas\n",
    "exact = exact.rename(index=str, columns={'Data de Criação':'qualified_date', 'Origem': 'type',\\\n",
    "                                        'Sub-Origem': 'sub_type', 'Etapa Atual': 'stage', 'Mercado':'vertical', \\\n",
    "                                        'Pontuação': 'score', 'Dt. Agend. reunião': 'scheduling_date',\\\n",
    "                                        'Dt. Reunião': 'meeting_date', 'Qualificação Feedback': 'feedback_score',\\\n",
    "                                        'Dt. Preenc. Feedback': 'feedback_date', 'Etapa Descarte': 'lost_stage',\\\n",
    "                                        'Data Descarte': 'lost_date', \\\n",
    "                                        'Nome do Vendedor': 'salesperson', 'Nome Pré-Vendedor':'sdr',\\\n",
    "                                        'E-mail Contato 1': 'email', 'Qualificação Filtro 1': 'filter1_score',\\\n",
    "                                        'Qualificação Filtro 2': 'filter2_score', 'Dt. Filtro 1' : 'filter1_date',\\\n",
    "                                        'Dt. Filtro 2': 'filter2_date'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##replaces de salespearson e sdr\n",
    "exact.salesperson.replace('Artur Mendes', 'artur', inplace=True)\n",
    "exact.salesperson.replace('Juliana Brito', 'juliana', inplace=True)\n",
    "exact.salesperson.replace('Daniela Degaspare', 'outros', inplace=True)\n",
    "exact.salesperson.replace('Rodrigo Ricco', 'outros', inplace=True)\n",
    "\n",
    "#sdr\n",
    "exact.sdr.replace('Letícia Lemos', 'leticia', inplace=True)\n",
    "exact.sdr.replace('Flávio Galvão', 'flavio', inplace=True)\n",
    "exact.sdr.replace('Israel Rodrigues', 'israel', inplace=True)\n",
    "exact.sdr.replace('Artur Pré-Venda', 'artur', inplace=True)\n",
    "exact.sdr.replace('Juliana Pré-Vendas', 'juliana', inplace=True)\n",
    "exact.sdr.replace('Alessandra Dias', 'outros', inplace=True)\n",
    "exact.sdr.replace('Flavia Lima', 'flavia', inplace=True)\n",
    "exact.sdr.replace('Daniela Pré-Vendas', 'outros', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##normalizar as datas\n",
    "exact['qualified_date'] = pd.DatetimeIndex(exact['qualified_date']).normalize()\n",
    "exact['scheduling_date'] = pd.DatetimeIndex(exact['scheduling_date']).normalize()\n",
    "exact['meeting_date'] = pd.DatetimeIndex(exact['meeting_date']).normalize()\n",
    "exact['feedback_date'] = pd.DatetimeIndex(exact['feedback_date']).normalize()\n",
    "exact['filter1_date'] = pd.DatetimeIndex(exact['filter1_date']).normalize()\n",
    "exact['filter2_date'] = pd.DatetimeIndex(exact['filter2_date']).normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Score em números para facilitar o dataset\n",
    "\n",
    "#feedbackscore\n",
    "exact.feedback_score.replace('Muito Quente', 4, inplace=True)\n",
    "exact.feedback_score.replace('Quente', 3, inplace=True)\n",
    "exact.feedback_score.replace('Morna', 2, inplace=True)\n",
    "exact.feedback_score.replace('Fria', 1, inplace=True)\n",
    "exact.feedback_score.replace('Congelada', 0, inplace=True)\n",
    "\n",
    "#filter1\n",
    "exact.filter1_score.replace('Muito Quente', 4, inplace=True)\n",
    "exact.filter1_score.replace('Quente', 3, inplace=True)\n",
    "exact.filter1_score.replace('Morna', 2, inplace=True)\n",
    "exact.filter1_score.replace('Fria', 1, inplace=True)\n",
    "exact.filter1_score.replace('Congelada', 0, inplace=True)\n",
    "\n",
    "#filter2\n",
    "exact.filter2_score.replace('Muito Quente', 4, inplace=True)\n",
    "exact.filter2_score.replace('Quente', 3, inplace=True)\n",
    "exact.filter2_score.replace('Morna', 2, inplace=True)\n",
    "exact.filter2_score.replace('Fria', 1, inplace=True)\n",
    "exact.filter2_score.replace('Congelada', 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Criar colunas para identificar até qual etapa de vendas o lead foi\n",
    "\n",
    "#entry, filter_one, filter_two, meeting, sales\n",
    "exact['entry'] = 1\n",
    "exact['filter_one'] = np.where(np.logical_or(np.isnan(exact.filter1_score),np.isnat(exact.filter1_date)), 0,1 )\n",
    "exact['filter_two'] = np.where(np.logical_or(np.isnan(exact.filter2_score),np.isnat(exact.filter2_date)), 0,1 )\n",
    "exact['meeting'] = np.where((np.isnan(exact.feedback_score)) & (np.isnat(exact.meeting_date)) & \\\n",
    "                            (np.isnat(exact.feedback_date)) & (np.isnat(exact.scheduling_date)),0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tempo entre etapas até o agendamento\n",
    "exact['time_to_filter1'] = ((exact.filter1_date - exact.qualified_date) / np.timedelta64(1, 'D'))\n",
    "exact.time_to_filter1 = exact.time_to_filter1.fillna(0)\n",
    "exact['time_to_filter2'] = ((exact.filter2_date - exact.filter1_date) / np.timedelta64(1, 'D'))\n",
    "exact.time_to_filter2 = exact.time_to_filter2.fillna(0)\n",
    "exact['time_to_meeting'] = ((exact.meeting_date - exact.filter2_date) / np.timedelta64(1, 'D'))\n",
    "exact.time_to_meeting = exact.time_to_meeting.fillna(0)\n",
    "exact['time_qualified_to_meeting'] = ((exact.meeting_date - exact.qualified_date) / np.timedelta64(1, 'D'))\n",
    "exact.time_qualified_to_meeting = exact.time_qualified_to_meeting.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['qualified_date', 'type', 'sub_type', 'vertical', 'CP: utm_campaign',\n",
       "       'CP: utm_source', 'CP: utm_medium', 'CP: Gerenciamento',\n",
       "       'CP: Número de funcionários', 'CP: Departamento',\n",
       "       'CP: Maiores desafios', 'stage', 'score', 'scheduling_date',\n",
       "       'meeting_date', 'feedback_score', 'feedback_date', 'lost_stage',\n",
       "       'salesperson', 'sdr', 'email', 'filter1_score', 'filter1_date',\n",
       "       'filter2_score', 'filter2_date', 'entry', 'filter_one', 'filter_two',\n",
       "       'meeting', 'time_to_filter1', 'time_to_filter2', 'time_to_meeting',\n",
       "       'time_qualified_to_meeting'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exact.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exact['opo_date'] = exact.loc[:, ['scheduling_date', 'meeting_date']].min(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Organizar as colunas na melhor ordem de trabalho\n",
    "exact = exact[['email', 'qualified_date','opo_date','vertical','type', 'sub_type', 'sdr', \\\n",
    "              'salesperson', 'score', 'filter1_score', 'filter2_score', \\\n",
    "              'feedback_score', 'entry', 'filter_one','time_to_filter1', 'stage', 'lost_stage',\\\n",
    "               'filter_two','time_to_filter2', 'meeting', 'time_to_meeting', 'time_qualified_to_meeting']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dropar linhas que não possuem emails\n",
    "exact.dropna(subset=['email'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#criar feature de target\n",
    "exact_meeting = exact[['email', 'meeting']]\n",
    "es_meeting_type = exact_meeting.drop_duplicates('email', keep='first').set_index('email')['meeting']\n",
    "rd['target'] = rd['email'].map(es_meeting_type)\n",
    "rd['target'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#hard time: criar coluna de tofu, mofu e bofu antes de virar MQL\n",
    "\n",
    "rd = rd.sort_values(by=['conv_date'], ascending=True)\n",
    "\n",
    "#etapa 1: subir uma coluna com a data de envio do lead para o time de vendas\n",
    "#etapa 2: criar uma tabela separada da 'rd' com os e-mails únicos\n",
    "#etapa 3: conseguir filtrar, para cada lead, a data de corte para contagem das conversões\n",
    "\n",
    "#etapa 1\n",
    "exact_create_date = exact[['email', 'qualified_date', 'type']]\n",
    "es_qualified_date = exact_create_date.drop_duplicates('email', keep='first').set_index('email')['qualified_date']\n",
    "rd['qualified_date'] = rd['email'].map(es_qualified_date)\n",
    "\n",
    "exact_opo_date = exact[['email', 'opo_date', 'type']]\n",
    "es_opo_date = exact_opo_date.drop_duplicates('email', keep='first').set_index('email')['opo_date']\n",
    "rd['opo_date'] = rd['email'].map(es_opo_date)\n",
    "\n",
    "es_type = exact_create_date.drop_duplicates('email', keep='first').set_index('email')['type']\n",
    "rd['type'] = rd['email'].map(es_type)\n",
    "\n",
    "exact_vertical = exact[['email', 'vertical']]\n",
    "es_vertical = exact_vertical.drop_duplicates('email', keep='first').set_index('email')['vertical']\n",
    "rd['vertical'] = rd['email'].map(es_vertical)\n",
    "\n",
    "exact_sdr = exact[['email', 'sdr']]\n",
    "es_sdr = exact_sdr.drop_duplicates('email', keep='first').set_index('email')['sdr']\n",
    "rd['sdr'] = rd['email'].map(es_sdr)\n",
    "\n",
    "exact_salesperson = exact[['email', 'salesperson']]\n",
    "es_salesperson = exact_salesperson.drop_duplicates('email', keep='first').set_index('email')['salesperson']\n",
    "rd['salesperson'] = rd['email'].map(es_salesperson)\n",
    "\n",
    "\n",
    "#sub etapa) criar coluna com variação entre data de qualificação para data de conversão\n",
    "rd['qualified-conv-date'] = ((rd.qualified_date - rd.conv_date) / np.timedelta64(1, 'D'))\n",
    "rd['qualified-conv-date'] = rd['qualified-conv-date'].fillna(0)\n",
    "\n",
    "#sub etapa 2) criar coluna com variação entre data de agendamento para data de conversão\n",
    "rd['opo-conv-date'] = ((rd.opo_date - rd.conv_date) / np.timedelta64(1, 'D'))\n",
    "rd['opo-conv-date'] = rd['opo-conv-date'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dropar eventos nulos\n",
    "rd = rd.dropna(axis=0, how='any', subset=['event'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#etapa 1a) criar dummies\n",
    "rd = pd.get_dummies(rd, columns=['funnel'], drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#etapa 2a) leads que já foram qualificados, contar somente as conversões antes de virar MQL\n",
    "rd2 = rd.copy()\n",
    "\n",
    "#base\n",
    "rd2 = rd2[rd2['opo-conv-date'] >= 0]\n",
    "rd2 = rd2[rd2['event'] != 'IntegracaoExact']\n",
    "\n",
    "#somar conversões por etapa do funil\n",
    "rd2['freq_infografico'] = rd2.groupby('email')['funnel_Infografico'].transform('sum')\n",
    "rd2['freq_planilha'] = rd2.groupby('email')['funnel_Planilha'].transform('sum')\n",
    "rd2['freq_webinar'] = rd2.groupby('email')['funnel_Webinar'].transform('sum')\n",
    "rd2['freq_checklist'] = rd2.groupby('email')['funnel_checklist'].transform('sum')\n",
    "rd2['freq_ebook'] = rd2.groupby('email')['funnel_ebook'].transform('sum')\n",
    "rd2['freq_kit'] = rd2.groupby('email')['funnel_kit'].transform('sum')\n",
    "rd2['freq_levantada_mao'] = rd2.groupby('email')['funnel_levantada_mao'].transform('sum')\n",
    "rd2['freq_newsletter'] = rd2.groupby('email')['funnel_newsletter'].transform('sum')\n",
    "rd2['freq_outros'] = rd2.groupby('email')['funnel_outros'].transform('sum')\n",
    "rd2['freq_pesquisa'] = rd2.groupby('email')['funnel_pesquisa'].transform('sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#drop nas colunas que não interessam (mantendo as colunas que interessam)\n",
    "rd2 = rd2[['conv_date', 'email', 'freq_infografico', 'freq_planilha', 'freq_webinar', 'freq_checklist',\\\n",
    "          'freq_ebook', 'freq_kit','freq_levantada_mao','freq_newsletter',  'freq_outros', 'freq_pesquisa']]\n",
    "\n",
    "rd2 = rd2.sort_values(by=['conv_date'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#incluir os dados na tabela rd\n",
    "rd_infografico = rd2.drop_duplicates('email', keep='first').set_index('email')['freq_infografico']\n",
    "rd['freq_infografico'] = rd['email'].map(rd_infografico)\n",
    "\n",
    "rd_planilha = rd2.drop_duplicates('email', keep='first').set_index('email')['freq_planilha']\n",
    "rd['freq_planilha'] = rd['email'].map(rd_planilha)\n",
    "\n",
    "rd_webinar = rd2.drop_duplicates('email', keep='first').set_index('email')['freq_webinar']\n",
    "rd['freq_webinar'] = rd['email'].map(rd_webinar)\n",
    "\n",
    "rd_checklist = rd2.drop_duplicates('email', keep='first').set_index('email')['freq_checklist']\n",
    "rd['freq_checklist'] = rd['email'].map(rd_checklist)\n",
    "\n",
    "rd_ebook = rd2.drop_duplicates('email', keep='first').set_index('email')['freq_ebook']\n",
    "rd['freq_ebook'] = rd['email'].map(rd_ebook)\n",
    "\n",
    "rd_kit = rd2.drop_duplicates('email', keep='first').set_index('email')['freq_kit']\n",
    "rd['freq_kit'] = rd['email'].map(rd_kit)\n",
    "\n",
    "rd_levantada = rd2.drop_duplicates('email', keep='first').set_index('email')['freq_levantada_mao']\n",
    "rd['freq_levantada_mao'] = rd['email'].map(rd_levantada)\n",
    "\n",
    "rd_newsletter = rd2.drop_duplicates('email', keep='first').set_index('email')['freq_newsletter']\n",
    "rd['freq_newsletter'] = rd['email'].map(rd_newsletter)\n",
    "\n",
    "rd_outros = rd2.drop_duplicates('email', keep='first').set_index('email')['freq_outros']\n",
    "rd['freq_outros'] = rd['email'].map(rd_outros)\n",
    "\n",
    "rd_pesquisa = rd2.drop_duplicates('email', keep='first').set_index('email')['freq_pesquisa']\n",
    "rd['freq_pesquisa'] = rd['email'].map(rd_pesquisa)\n",
    "\n",
    "rd = rd[rd['event'] != 'IntegracaoExact']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#puxar a primeira origem do lead\n",
    "rd_source_first_conv = rd.drop_duplicates('email', keep='first').set_index('email', 'conv_date')['rd_medium']\n",
    "rd_source_first_conv.sort_values(ascending=True)\n",
    "rd['source_first_conv'] = rd['email'].map(rd_source_first_conv)\n",
    "\n",
    "#puxar a primeira conversão do lead\n",
    "rd_event_first_conv = rd.drop_duplicates('email', keep='first').set_index('email', 'conv_date')['event']\n",
    "rd_event_first_conv.sort_values(ascending=True)\n",
    "rd['event_first_conv'] = rd['email'].map(rd_event_first_conv)\n",
    "\n",
    "\n",
    "#puxar a última origem do lead\n",
    "rd_source_last_conv = rd.drop_duplicates('email', keep='last').set_index('email', 'conv_date')['rd_medium']\n",
    "rd_source_last_conv.sort_values(ascending=False)\n",
    "rd['source_last_conv'] = rd['email'].map(rd_source_last_conv)\n",
    "\n",
    "#puxar a primeira conversão do lead\n",
    "rd_event_last_conv = rd.drop_duplicates('email', keep='last').set_index('email', 'conv_date')['event']\n",
    "rd_event_last_conv.sort_values(ascending=False)\n",
    "rd['event_last_conv'] = rd['email'].map(rd_event_last_conv)\n",
    "\n",
    "#puxar o número total de conversões\n",
    "rd_conversions = pd.DataFrame()\n",
    "rd_conversions['email'] = rd['email']\n",
    "rd_conversions['freq'] = rd_conversions.groupby('email')['email'].transform('count')\n",
    "rd_conversions = rd_conversions.drop_duplicates('email', keep='first').set_index('email')['freq']\n",
    "rd['conversions'] = rd['email'].map(rd_conversions)\n",
    "rd['conversions']=rd['conversions'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vitor.Souza\\Documents\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "C:\\Users\\Vitor.Souza\\Documents\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n",
      "C:\\Users\\Vitor.Souza\\Documents\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Vitor.Souza\\Documents\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Vitor.Souza\\Documents\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Vitor.Souza\\Documents\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Vitor.Souza\\Documents\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Vitor.Souza\\Documents\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Vitor.Souza\\Documents\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Vitor.Souza\\Documents\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#colunas de management, job_title e outras classificações que podem vir em outras conversões\n",
    "rd4 = rd.copy()\n",
    "rd4 = rd4.sort_values(by=['conv_date'], ascending=True)\n",
    "\n",
    "#site\n",
    "rd_site = rd4[['email', 'site']]\n",
    "rd_site.dropna(axis=0, how='any', inplace=True)\n",
    "rd_site = rd_site.drop_duplicates('email', keep='first').set_index('email')['site']\n",
    "rd['site'] = rd['email'].map(rd_site)\n",
    "\n",
    "#utm_campaign\n",
    "rd_utm_campaign = rd4[['email', 'utm_campaign']]\n",
    "rd_utm_campaign.dropna(axis=0, how='any', inplace=True)\n",
    "rd_utm_campaign = rd_utm_campaign.drop_duplicates('email', keep='first').set_index('email')['utm_campaign']\n",
    "rd['utm_campaign'] = rd['email'].map(rd_utm_campaign)\n",
    "\n",
    "#utm_medium\n",
    "rd_utm_medium = rd4[['email', 'utm_medium']]\n",
    "rd_utm_medium.dropna(axis=0, how='any', inplace=True)\n",
    "rd_utm_medium = rd_utm_medium.drop_duplicates('email', keep='first').set_index('email')['utm_medium']\n",
    "rd['utm_medium'] = rd['email'].map(rd_utm_medium)\n",
    "\n",
    "#utm_source\n",
    "rd_utm_source = rd4[['email', 'utm_source']]\n",
    "rd_utm_source.dropna(axis=0, how='any', inplace=True)\n",
    "rd_utm_source = rd_utm_source.drop_duplicates('email', keep='first').set_index('email')['utm_source']\n",
    "rd['utm_source'] = rd['email'].map(rd_utm_source)\n",
    "\n",
    "#rd_medium\n",
    "rd_rd_medium = rd4[['email', 'rd_medium']]\n",
    "rd_rd_medium.dropna(axis=0, how='any', inplace=True)\n",
    "rd_rd_medium = rd_rd_medium.drop_duplicates('email', keep='first').set_index('email')['rd_medium']\n",
    "rd['rd_medium'] = rd['email'].map(rd_rd_medium)\n",
    "\n",
    "#rd_source\n",
    "rd_rd_source = rd4[['email', 'rd_source']]\n",
    "rd_rd_source.dropna(axis=0, how='any', inplace=True)\n",
    "rd_rd_source = rd_rd_source.drop_duplicates('email', keep='first').set_index('email')['rd_source']\n",
    "rd['rd_source'] = rd['email'].map(rd_rd_source)\n",
    "\n",
    "#department\n",
    "rd_department = rd4[['email', 'department']]\n",
    "rd_department.dropna(axis=0, how='any', inplace=True)\n",
    "rd_department = rd_department.drop_duplicates('email', keep='first').set_index('email')['department']\n",
    "rd['department'] = rd['email'].map(rd_department)\n",
    "\n",
    "#n_employees\n",
    "rd_n_employees = rd4[['email', 'n_employees']]\n",
    "rd_n_employees.dropna(axis=0, how='any', inplace=True)\n",
    "rd_n_employees = rd_n_employees.drop_duplicates('email', keep='first').set_index('email')['n_employees']\n",
    "rd['n_employees'] = rd['email'].map(rd_n_employees)\n",
    "\n",
    "#management\n",
    "rd_management = rd4[['email', 'management']]\n",
    "rd_management.dropna(axis=0, how='any', inplace=True)\n",
    "rd_management = rd_management.drop_duplicates('email', keep='first').set_index('email')['management']\n",
    "rd['management'] = rd['email'].map(rd_management)\n",
    "\n",
    "#job_title\n",
    "rd_job_title = rd4[['email', 'job_title']]\n",
    "rd_job_title.dropna(axis=0, how='any', inplace=True)\n",
    "rd_job_title = rd_job_title.drop_duplicates('email', keep='first').set_index('email')['job_title']\n",
    "rd['job_title'] = rd['email'].map(rd_job_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#validação do email (corporativo ou não)\n",
    "\n",
    "#load da base\n",
    "free_domain = pd.read_csv('data/free_domain_list.csv', sep=',')\n",
    "\n",
    "#criar coluna categórica (0 para free e 1 para diferente da free)\n",
    "free_domain['domain_type'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#criar uma coluna com domain\n",
    "rd['email_domain'] = rd['email'].str.split('@').str[1]\n",
    "rd['email_domain'] = rd['email_domain'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#puxar os dados da tabela free_domain\n",
    "rd_free_domain = free_domain.drop_duplicates('domain', keep='first').set_index('domain')['domain_type']\n",
    "rd['email_domain_type'] = rd['email_domain'].map(rd_free_domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#preencher com 1 os valores vazios\n",
    "rd.email_domain_type.fillna(1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Integração com os dados do pipedrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipedrive = pd.read_csv('data/pipedrive.csv', sep=',', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipedrive['Deal - Data atualizada'] = pd.DatetimeIndex(pipedrive['Deal - Data atualizada']).normalize()\n",
    "pipedrive['Deal - Data de perda'] = pd.DatetimeIndex(pipedrive['Deal - Data de perda']).normalize()\n",
    "pipedrive['Deal - Negócio criado em'] = pd.DatetimeIndex(pipedrive['Deal - Negócio criado em']).normalize()\n",
    "pipedrive['Deal - Última alteração de etapa'] = pd.DatetimeIndex(pipedrive['Deal - Última alteração de etapa']).normalize()\n",
    "pipedrive['Deal - Data de ganho'] = pd.DatetimeIndex(pipedrive['Deal - Data de ganho']).normalize()\n",
    "pipedrive['Deal - Data da Próxima Atividade'] = pd.DatetimeIndex(pipedrive['Deal - Data da Próxima Atividade']).normalize()\n",
    "pipedrive['Deal - Data da Última Atividade'] = pd.DatetimeIndex(pipedrive['Deal - Data da Última Atividade']).normalize()\n",
    "pipedrive['Deal - Data de fechamento esperada'] = pd.DatetimeIndex(pipedrive['Deal - Data de fechamento esperada']).normalize()\n",
    "pipedrive['Deal - Negócio fechado em'] = pd.DatetimeIndex(pipedrive['Deal - Negócio fechado em']).normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "create = pipedrive['Deal - Negócio criado em']\n",
    "pipedrive.drop(labels=['Deal - Negócio criado em'], axis=1,inplace = True)\n",
    "pipedrive.insert(0, 'Create', create)\n",
    "\n",
    "email = pipedrive['Person - E-mail']\n",
    "pipedrive.drop(labels=['Person - E-mail'], axis=1,inplace = True)\n",
    "pipedrive.insert(1, 'email', email)\n",
    "\n",
    "\n",
    "pipedrive.reset_index(inplace=True)\n",
    "pipedrive.drop(labels=['index'], axis=1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Encontrar campos com emails duplos\n",
    "pipedrive['2 Emails'] = np.where(pipedrive['email'].str.contains(',' or '/'),1,0)\n",
    "pipedrive = pipedrive.sort_values(by='2 Emails', ascending=False)\n",
    "pipedrive['2 Emails'].value_counts()\n",
    "pipedrive['Email 1'], pipedrive['Email 2'], pipedrive['Email 3'] = pipedrive['email'].str.split(',' or '/', 2).str\n",
    "pipedrive['binary'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vitor.Souza\\Documents\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "##Pipedrive\n",
    "#final['is_pipedrive']\n",
    "pp_ispipedrive = pipedrive[['email', 'binary']]\n",
    "pp_ispipedrive.drop_duplicates('email', inplace=True)\n",
    "pp_ispipedrive.set_index('email', inplace=True)\n",
    "rd = rd.join(pp_ispipedrive, on='email', how='left', lsuffix='_final', rsuffix='_pipedrive')\n",
    "rd['is_pipedrive'] = rd['binary']\n",
    "rd.drop('binary', inplace=True, axis=1)\n",
    "rd['is_pipedrive']=rd['is_pipedrive'].fillna(0)\n",
    "\n",
    "#final['value_pndr']\n",
    "pp_value_pndr = pipedrive.drop_duplicates('email', keep='first').set_index('email')['Deal - Valor']\n",
    "pp_value_pndr.sort_values(ascending=True)\n",
    "rd['value_pndr'] = rd['email'].map(pp_value_pndr)\n",
    "\n",
    "#final['negociation_step']\n",
    "pp_negociation_step = pipedrive.drop_duplicates('email', keep='first').set_index('email')['Deal - Etapa']\n",
    "pp_negociation_step.sort_values(ascending=True)\n",
    "rd['negociation_step'] = rd['email'].map(pp_negociation_step)\n",
    "\n",
    "#final['opo_status']\n",
    "pp_opo_status = pipedrive.drop_duplicates('email', keep='first').set_index('email')['Deal - Status']\n",
    "pp_opo_status.sort_values(ascending=True)\n",
    "rd['opo_status'] = rd['email'].map(pp_opo_status)\n",
    "\n",
    "#final['activities_done']\n",
    "pp_activities_done = pipedrive.drop_duplicates('email', keep='first').set_index('email')['Deal - Atividades concluídas']\n",
    "pp_activities_done.sort_values(ascending=True)\n",
    "rd['activities_done'] = rd['email'].map(pp_activities_done)\n",
    "\n",
    "#final['pipe_lost_date']\n",
    "pp_pipe_lost_date = pipedrive.drop_duplicates('email', keep='first').set_index('email')['Deal - Data de perda']\n",
    "pp_pipe_lost_date.sort_values(ascending=True)\n",
    "rd['pipe_lost_date'] = rd['email'].map(pp_pipe_lost_date)\n",
    "\n",
    "#final['pipe_won_date']\n",
    "pp_pipe_won_date = pipedrive.drop_duplicates('email', keep='first').set_index('email')['Deal - Data de ganho']\n",
    "pp_pipe_won_date.sort_values(ascending=True)\n",
    "rd['pipe_won_date'] = rd['email'].map(pp_pipe_won_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finalizando o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#finalizando o dataset\n",
    "final = rd.copy()\n",
    "final = final.sort_values(by=['conv_date'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#etapa 5: criar uma tabela com e-mails únicos\n",
    "df = final.drop_duplicates(subset='email', keep='first').reset_index()\n",
    "df.drop(labels=['index'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#preencher blanks com NaN\n",
    "for i in range(0,len(df.columns)):\n",
    "    name = df.columns[i]\n",
    "    df[df.columns[i]].replace(r'^\\s*$', np.nan, regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#diminuir a quantidade de labels dentro das colunas de categoria\n",
    "\n",
    "#job_title em: champion, first_contact e others\n",
    "df.job_title.replace('Sócio / CEO', 'champion', inplace=True)\n",
    "df.job_title.replace('Diretor', 'champion', inplace=True)\n",
    "df.job_title.replace('Gerente', 'champion', inplace=True)\n",
    "\n",
    "#first_contact\n",
    "df.job_title.replace('Coordenador', 'non_champion', inplace=True)\n",
    "df.job_title.replace('Supervisor', 'non_champion', inplace=True)\n",
    "df.job_title.replace('Analista', 'non_champion', inplace=True)\n",
    "\n",
    "#others\n",
    "df.job_title.replace('Outros Cargos', 'others', inplace=True)\n",
    "df.job_title.replace('Estudante/Estagiário', 'others', inplace=True)\n",
    "df.job_title.replace('Vendedor / atendente', 'others', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#department\n",
    "\n",
    "#helpdesk/ti\n",
    "df.department.replace('TI / Suporte / Helpdesk', 'helpdesk_ti', inplace=True)\n",
    "df.department.replace('TI', 'helpdesk_ti', inplace=True)\n",
    "\n",
    "#atendimento\n",
    "df.department.replace('Atendimento ao cliente', 'atendimento', inplace=True)\n",
    "\n",
    "#vendas/marketing\n",
    "df.department.replace('Vendas / Comercial', 'comercial', inplace=True)\n",
    "df.department.replace('Marketing', 'comercial', inplace=True)\n",
    "df.department.replace('Vendas / Comercial ', 'comercial', inplace=True)\n",
    "df.department.replace('Comercial', 'comercial', inplace=True)\n",
    "\n",
    "#contabilidade\n",
    "df.department.replace('Finanças/contabilidade', 'contabilidade', inplace=True)\n",
    "df.department.replace('Finanças / Contabilidade', 'contabilidade', inplace=True)\n",
    "df.department.replace('Contabilidade', 'contabilidade', inplace=True)\n",
    "\n",
    "#rh\n",
    "df.department.replace('Recursos humanos', 'rh', inplace=True)\n",
    "df.department.replace('Recursos humanos ', 'rh', inplace=True)\n",
    "df.department.replace('RH', 'rh', inplace=True)\n",
    "#outros\n",
    "df.department.replace('Consultoria / serviços profissionais', 'outros', inplace=True)\n",
    "df.department.replace('Compras', 'outros', inplace=True)\n",
    "df.department.replace('Consultoria/serviços profissionais', 'outros', inplace=True)\n",
    "df.department.replace('Jurídico', 'outros', inplace=True)\n",
    "df.department.replace('Instalações', 'outros', inplace=True)\n",
    "df.department.replace('Serviço compartilhado', 'outros', inplace=True)\n",
    "df.department.replace('Outros', 'outros', inplace=True)\n",
    "df.department.replace('Planejamento', 'outros', inplace=True)\n",
    "df.department.replace('Financeiro', 'outros', inplace=True)\n",
    "df.department.replace('Presidência', 'outros', inplace=True)\n",
    "df.department.replace('Controladoria', 'outros', inplace=True)\n",
    "df.department.replace('Custos e Orçamento', 'outros', inplace=True)\n",
    "df.department.replace('Logística', 'outros', inplace=True)\n",
    "df.department.replace('Operação / Produção', 'outros', inplace=True)\n",
    "df.department.replace('Outro', 'outros', inplace=True)\n",
    "df.department.replace('Administrativo', 'outros', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#management\n",
    "\n",
    "#imaturo (não faz gerenciamento)\n",
    "df.management.replace('Não temos atendimentos para gerenciar', 'imaturo', inplace=True)\n",
    "df.management.replace('Não gerenciamos os atendimentos', 'imaturo', inplace=True)\n",
    "\n",
    "#iniciante(planilha e e-mail)\n",
    "df.management.replace('Planilha', 'iniciante', inplace=True)\n",
    "df.management.replace('E-mail', 'iniciante', inplace=True)\n",
    "\n",
    "#intermediario(sistema de erp e loja virtual)\n",
    "df.management.replace('Sistema de gestão (ERP)', 'intermediario', inplace=True)\n",
    "df.management.replace('Sistema de gestão(ERP)', 'intermediario', inplace=True)\n",
    "df.management.replace('Sistema de E-Commerce (Loja virtual)', 'intermediario', inplace=True)\n",
    "df.management.replace('Sistema de E-commerce (Loja virtual)', 'intermediario', inplace=True)\n",
    "\n",
    "#avancado (sistema de helpdesk e sistema interno)\n",
    "df.management.replace('Sistema de atendimento / helpdesk (CRM)', 'avancado', inplace=True)\n",
    "df.management.replace('Sistema interno', 'avancado', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#n_employees\n",
    "df.n_employees.replace('de 1 a 10', '1-10', inplace=True)\n",
    "df.n_employees.replace('acima de 100', '101+', inplace=True)\n",
    "df.n_employees.replace('de 11 a 30', '11-30', inplace=True)\n",
    "df.n_employees.replace('de 31 a 50', '31-50', inplace=True)\n",
    "df.n_employees.replace('de 51 a 100', '51-100', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#email (vou considerar que leads gerados por e-mail são leads comarketing, já que a estratégia outbound não há um volume significado\n",
    "df.rd_medium.replace('Email', 'comarketing', inplace=True)\n",
    "\n",
    "#ajuste das categorias para facilitar a análise\n",
    "df.rd_medium.replace('Busca Orgânica', 'organic', inplace=True)\n",
    "df.rd_medium.replace('Busca Paga', 'gsearch', inplace=True)\n",
    "df.rd_medium.replace('Display', 'gdisplay', inplace=True)\n",
    "df.rd_medium.replace('Facebook', 'facebook', inplace=True)\n",
    "df.rd_medium.replace('LinkedIn', 'linkedin', inplace=True)\n",
    "\n",
    "#adotar tráfego direto e referência como word_of_mouth\n",
    "df.rd_medium.replace('Tráfego Direto', 'wom', inplace=True)\n",
    "df.rd_medium.replace('Referência', 'wom', inplace=True)\n",
    "\n",
    "#Somar Outros com Desconhecido, já que tem o mesmo peso\n",
    "df.rd_medium.replace('Outros', 'Desconhecido', inplace=True)\n",
    "df.rd_medium.replace('Desconhecido', 'desconhecido', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#type\n",
    "df.type.replace('Inbound', 'levantada_mao', inplace=True)\n",
    "df.type.replace('Outbound', 'outbound', inplace=True)\n",
    "df.type.replace('InboundContent', 'lead_scoring', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['is_lead'] = 1\n",
    "df['is_mql'] = np.where(np.isnat(df.qualified_date), 0, 1)\n",
    "df['is_opo'] = np.where(np.isnat(df.opo_date), 0, 1)\n",
    "df['is_client'] = np.where(np.isnat(df.pipe_won_date), 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['refresh_date'] = df.loc[:, ['conv_date', 'qualified_date', 'opo_date', 'pipe_won_date']].max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#week, month and year lead\n",
    "df['week_lead'] = df['conv_date'].dt.week\n",
    "df['month_lead'] = df['conv_date'].dt.month\n",
    "df['year_lead'] = df['conv_date'].dt.year\n",
    "\n",
    "#week, month and year mql\n",
    "df['week_mql'] = df['qualified_date'].dt.week\n",
    "df['month_mql'] = df['qualified_date'].dt.month\n",
    "df['year_mql'] = df['qualified_date'].dt.year\n",
    "\n",
    "#week, month and year opo\n",
    "df['week_opo'] = df['opo_date'].dt.week\n",
    "df['month_opo'] = df['opo_date'].dt.month\n",
    "df['year_opo'] = df['opo_date'].dt.year\n",
    "\n",
    "#week, month and year sales\n",
    "df['week_sales'] = df['pipe_won_date'].dt.week\n",
    "df['month_sales'] = df['pipe_won_date'].dt.month\n",
    "df['year_sales'] = df['pipe_won_date'].dt.year\n",
    "\n",
    "#week, month and year refresh date\n",
    "df['week_refresh'] = df['refresh_date'].dt.week\n",
    "df['month_refresh'] = df['refresh_date'].dt.month\n",
    "df['year_refresh'] = df['refresh_date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropar colunas que não interessam\n",
    "df.columns\n",
    "df.drop(labels=['event', 'Custom fields[44611]', 'Custom fields[44612]', 'Custom fields[265]', 'company_name',\\\n",
    "                'name', 'phone', 'site', 'utm_content', 'utm_term', 'funnel_Infografico', \\\n",
    "                'funnel_Planilha', 'funnel_Webinar','funnel_checklist', 'funnel_ebook', 'funnel_kit', \\\n",
    "                'funnel_levantada_mao', 'funnel_newsletter', 'funnel_outros', 'funnel_pesquisa', 'event'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.vertical.replace('Administrador de Condomínio','sem_preenchimento', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_excel('database.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre processing and Discovery analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categorical_features = df.select_dtypes(include=['object']).axes[1] # retorna as vars que são do tipo objeto\n",
    "\n",
    "# unique: retorna os valores únicos\n",
    "# nunique: retorna o número de valores únicos\n",
    "for col in categorical_features:\n",
    "    print (col, df[col].nunique()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.factorplot(x=\"job_title\",\n",
    "                    data=df, kind=\"count\",\n",
    "                    size=4, aspect=3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.factorplot(x=\"department\",\n",
    "                    data=df, kind=\"count\",\n",
    "                    size=4, aspect=3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.factorplot(x=\"n_employees\",\n",
    "                    data=df, kind=\"count\",\n",
    "                    size=4, aspect=3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.factorplot(x=\"management\",\n",
    "                    data=df, kind=\"count\",\n",
    "                    size=4, aspect=3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.factorplot(x=\"rd_medium\",\n",
    "                    data=df, kind=\"count\",\n",
    "                    size=4, aspect=3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame.hist(df, figsize = [15,15]);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
