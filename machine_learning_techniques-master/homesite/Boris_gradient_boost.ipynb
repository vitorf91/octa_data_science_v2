{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homesite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import csv\n",
    "from sklearn import linear_model\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "from sklearn import svm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import PolynomialFeatures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ReplaceWithDummies(column, *DataFrames):\n",
    "    #The purpose of this function is to replace a column of type 'object' with n distict values,\n",
    "    #common to all DataFrames passed in\n",
    "    #For example train and test data sets, with n-1 boolean columns as delete the original culmnn\n",
    "    for df in DataFrames: #Make sure the column is actually in all data frames\n",
    "        if column not in df.columns:\n",
    "            print('column not found')\n",
    "            return None\n",
    "    size=[]\n",
    "    for df in DataFrames:\n",
    "        size.append(df.shape[0])\n",
    "    \n",
    "    long_column=[]\n",
    "    for i in range(len(DataFrames)):\n",
    "        long_column.append(DataFrames[i][column])\n",
    "    long_column = pd.concat(long_column)\n",
    "    dummies = pd.get_dummies(long_column)\n",
    "    dummies.drop(list(dummies.columns)[0], axis=1, inplace=True) # dropping one column from dummies\n",
    "    \n",
    "    Dummies =[] # As list of dummies to append to the list of DataFrames in order \n",
    "    for s in size:\n",
    "        Dummies.append(dummies[:s])\n",
    "        dummies=dummies[s:]\n",
    "    \n",
    "    #drop the column that needs replacing\n",
    "    for df in DataFrames:\n",
    "        df.drop(column, axis=1, inplace=True)\n",
    "\n",
    "    \n",
    "    #Now append the dummy variables:\n",
    "\n",
    "    for i,df in enumerate(DataFrames):\n",
    "        for column_type in Dummies[i]:     \n",
    "            new_name=str(column) +'_'+ str(column_type)\n",
    "            df[new_name]=Dummies[i][column_type]\n",
    "    return DataFrames\n",
    "    \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tr=pd.read_csv('train.csv')\n",
    "te=pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Run for local testing\n",
    "n= len(tr)\n",
    "n = int(n*(float(2)/float(3)))\n",
    "train = copy.deepcopy(tr[:n])\n",
    "m=int((len(tr)-n)/2)\n",
    "validation = copy.deepcopy(tr[n:n+m])\n",
    "test = copy.deepcopy(tr[n+m:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Use this for the real thing\n",
    "train = tr[:]\n",
    "validation = te[:]\n",
    "test=te[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/blerner/anaconda/lib/python3.4/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/blerner/anaconda/lib/python3.4/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/blerner/anaconda/lib/python3.4/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/blerner/anaconda/lib/python3.4/site-packages/pandas/core/generic.py:2862: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "/Users/blerner/anaconda/lib/python3.4/site-packages/pandas/core/generic.py:3117: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "#Converts date to an int. Seems to work better than previous attemopts of using categorical variables.\n",
    "\n",
    "ALL = [train, validation, test]\n",
    "for frame in ALL:\n",
    "    frame.drop('QuoteNumber', axis=1, inplace=True)\n",
    "    frame['Original_Quote_Date']= pd.to_datetime(frame['Original_Quote_Date'])\n",
    "    frame['Original_Quote_Date'] = frame['Original_Quote_Date'].astype(int)\n",
    "    for c in frame:\n",
    "        frame[c].fillna(0, inplace=True)\n",
    "        frame[c].replace(-1, 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173836"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/blerner/anaconda/lib/python3.4/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#dropping useless columns\n",
    "for c in train.drop('QuoteConversion_Flag', axis=1):\n",
    "    x=train[c].unique()\n",
    "    if len(x) < 2:\n",
    "        for frame in ALL:\n",
    "            frame.drop(c, axis=1, inplace=True)\n",
    "#rescaling\n",
    "for c in train.drop('QuoteConversion_Flag', axis=1):\n",
    "    if train[c].dtype != 'object':\n",
    "        mean=train[c].mean()\n",
    "        std = train[c].std()\n",
    "        if std > 0.0001:\n",
    "            for frame in ALL:\n",
    "                frame = (frame[c]-mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/blerner/anaconda/lib/python3.4/site-packages/ipykernel/__main__.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/blerner/anaconda/lib/python3.4/site-packages/ipykernel/__main__.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#Replacing all categorical variables with dummy variables\n",
    "for column in train:\n",
    "    if train[column].dtype == 'object':\n",
    "        [train, validation, test] = ReplaceWithDummies(column, train, validation, test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Run this for partial\n",
    "\n",
    "X_train=train.drop('QuoteConversion_Flag', axis=1)\n",
    "X_test=test.drop('QuoteConversion_Flag', axis=1)\n",
    "X_validation=test.drop('QuoteConversion_Flag', axis=1)\n",
    "y_train=train['QuoteConversion_Flag']\n",
    "y_test=test['QuoteConversion_Flag']\n",
    "y_validation=validation['QuoteConversion_Flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Run this for full\n",
    "X_train=train.drop('QuoteConversion_Flag', axis=1)\n",
    "y_train=train['QuoteConversion_Flag']\n",
    "X_validation= validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173836"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Support Vector machine\n",
    "model_svc = svm.SVC()\n",
    "model_svc.fit(X_train, y_train)\n",
    "print(sum(y_train))\n",
    "print(1-sum(abs(np.array(y_train)-np.array(model_svc.predict(X_train))))/float(len(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(260753, 601)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Poly\n",
    "pca = PCA(n_components=550) #Instantiate the model & set parameters\n",
    "pca.fit(X_train); #Fit the model\n",
    "X_train_red = pca.transform(X_train)\n",
    "X_validation_red = pca.transform(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#introduce interaction terms\n",
    "poly = PolynomialFeatures()\n",
    "poly.fit(X_train_red)\n",
    "X_train_poly=poly.transform(X_train_red)\n",
    "X_validation_poly = poly.transform(X_validation_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(260753, 1326)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_poly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_red.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Logistioc regression\n",
    "model = linear_model.LogisticRegression(C=0.1)\n",
    "model.fit(X_train, y_train)\n",
    "predictions=model.predict_proba(X_validation)[:,1]\n",
    "#print(sum(y_train))\n",
    "#print(1-sum(abs(np.array(y_train)-np.array(model.predict(X_train))))/float(len(y_train)))\n",
    "#p1=model.predict(validation)\n",
    "#print(sum(y_validation))\n",
    "#print(1-sum(abs(np.array(y_validation)-np.array(model.predict(X_validation))))/float(len(y_validation)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Gradient boosting \n",
    "model_xgb = xgb.DMatrix(np.array(X_train), label=np.array(y_train))\n",
    "bst = xgb.train({'objective':'reg:logistic'},dtrain=model_xgb)\n",
    "predictions = bst.predict(xgb.DMatrix(X_validation))\n",
    "#predictions = bst.predict(xgb.DMatrix(X_train))\n",
    "#predictions_binary = []\n",
    "#for x in list(predictions):\n",
    "#    if x>=0.5:\n",
    "#        predictions_binary.append(1)\n",
    "#    else:\n",
    "#        predictions_binary.append(0)\n",
    "\n",
    "#print(sum(y_train))\n",
    "#print(1-sum(abs(np.array(y_train)-np.array(predictions_binary)))/float(len(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173836"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = bst.predict(xgb.DMatrix(X_validation))\n",
    "#predictions_binary = []\n",
    "#for x in list(predictions):\n",
    "#    if x>=0.5:\n",
    "#        predictions_binary.append(1)\n",
    "#    else:\n",
    "#        predictions_binary.append(0)\n",
    "#print(sum(y_train))\n",
    "#print(1-sum(abs(np.array(y_validation)-np.array(predictions_binary)))/float(len(y_validation)))\n",
    "#p2=predictions_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Let's try random forest\n",
    "\n",
    "rfc_model = RandomForestClassifier(n_estimators = 10, n_jobs=-1)\n",
    "rfc_model.fit(X_train,y_train)\n",
    "print(sum(y_train))\n",
    "print(1-sum(abs(np.array(y_train)-np.array(rfc_model.predict(X_train))))/float(len(y_train)))\n",
    "#predict2=rfc_model.predict(validation)\n",
    "#print(sum(y_validation))\n",
    "#print(1-sum(abs(np.array(y_validation)-np.array(rfc_model.predict(X_validation))))/float(len(y_validation)))\n",
    "p3=rfc_model.predict(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Not run for full\n",
    "ensemble_train =list(np.logical_or(np.array(p1),np.array(p2), np.array(p3)))\n",
    "ensemble_train = int(ensemble_train==1)\n",
    "print(1-sum(abs(np.array(y_train)-np.array(ensemble_train)))/float(len(y_train)))\n",
    "\n",
    "ensemble_validation =list(np.logical_or(np.array(model.predict(X_validation)),np.array(rfc_model.predict(X_validation))))\n",
    "ensemble_validation = int(ensemble_validation==1)\n",
    "print(1-sum(abs(np.array(y_validation)-np.array(ensemble_validation)))/float(len(y_validation)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ensemble_predict =np.logical_or(np.array(p1),np.array(p2), np.array(p3)).astype(int)\n",
    "len(ensemble_predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#creates the ouput to be submitted\n",
    "output =pd.DataFrame()\n",
    "output[\"QuoteNumber\"] = te[\"QuoteNumber\"]\n",
    "output[\"QuoteConversion_Flag\"] = predictions\n",
    "output.to_csv(\"output_boost_newdate.csv\", index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#attempt at neural network: not working right now\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Dense(64) is a fully-connected layer with 64 hidden units.\n",
    "# in the first layer, you must specify the expected input data shape:\n",
    "# here, 20-dimensional vectors.\n",
    "model.add(Dense(64, input_dim=584, init='uniform'))\n",
    "#model.add(Activation('tanh'))\n",
    "#model.add(Dropout(0.5))\n",
    "#model.add(Dense(64, init='uniform'))\n",
    "#model.add(Activation('tanh'))\n",
    "#model.add(Dropout(0.5))\n",
    "#model.add(Dense(2, init='uniform'))\n",
    "#model.add(Activation('softmax'))\n",
    "\n",
    "#sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "\n",
    "model.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/mpearmain/homesite-quote-conversion/xgboost-benchmark/discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
